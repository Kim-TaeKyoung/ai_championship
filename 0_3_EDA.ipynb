{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0-3.EDA.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kim-TaeKyoung/a/blob/main/0_3_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK0F8DHAHFce"
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsmweV43G-nT"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import json\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFFZRk90FMHR"
      },
      "source": [
        "train_path = glob(\"/content/drive/MyDrive/Colab/AI_ChampionShip/dataset/raw/kdx-dataset/train/*.mp4\")\n",
        "test_path = glob(\"/content/drive/MyDrive/Colab/AI_ChampionShip/dataset/raw/kdx-dataset/test/*.mp4\")\n",
        "annJson = glob(\"/content/drive/MyDrive/Colab/AI_ChampionShip/dataset/raw/kdx-dataset/train/*.json\")\n",
        "TrainList = sorted(train_path)\n",
        "\n",
        "with open(annJson[0], 'r') as f:\n",
        "    fire_scenes = json.load(f)\n",
        "fireScenesList = list(fire_scenes)\n",
        "\n",
        "num_video_files = len(fire_scenes.keys())\n",
        "print('Train 영상은 {}개 입니다'.format(num_video_files))\n",
        "print('Test 영상은 {}개 입니다'.format(len(test_path)))\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "\n",
        "for idx, val in enumerate(fireScenesList):\n",
        "    vidCap = cv2.VideoCapture(TrainList[idx])\n",
        "    jsonParse = fire_scenes[val]\n",
        "\n",
        "    if not jsonParse['scenes']:\n",
        "        continue\n",
        "\n",
        "    else:\n",
        "\n",
        "        if not vidCap.isOpened():\n",
        "            print(\"could not open :\", val)\n",
        "            exit(0)\n",
        "\n",
        "        if val == TrainList[idx].split('/')[-1]:\n",
        "            width = vidCap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "            height = vidCap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "            fps = round(vidCap.get(cv2.CAP_PROP_FPS))\n",
        "            print('Video Name: ', val)\n",
        "            print('Video Resolution: %d, %d' % (width, height))\n",
        "            print('Frame Count:', int(vidCap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "            print('openCV_FPS:', fps)\n",
        "            print('PlayTime:', jsonParse['duration'])\n",
        "            print('FPS:', vidCap.get(cv2.CAP_PROP_FRAME_COUNT) / jsonParse['duration'])\n",
        "            print(vidCap.get(cv2.CAP_PROP_POS_AVI_RATIO))\n",
        "            print(vidCap.get(cv2.CAP_PROP_POS_MSEC))\n",
        "\n",
        "            n = 0\n",
        "            k = len(jsonParse['scenes'])\n",
        "            videoCount = 1\n",
        "            print(jsonParse['scenes'])\n",
        "            print('Label 개수:', k)\n",
        "            print('==' * 10)\n",
        "\n",
        "            while vidCap.isOpened():\n",
        "                ret, image = vidCap.read()\n",
        "\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                # 이미지 리사이즈\n",
        "                frame = cv2.resize(image, (1000, 600))\n",
        "                #가우시안 블러처리\n",
        "                blur = cv2.GaussianBlur(frame, (21, 21), 0)\n",
        "                #HSV로 변환\n",
        "                hsv = cv2.cvtColor(blur, cv2.COLOR_BGR2HSV)\n",
        "                #HSV 경계값 설정\n",
        "                lower = [18, 50, 50]\n",
        "                upper = [35, 255, 255]\n",
        "\n",
        "                lower = np.array(lower, dtype='uint8')\n",
        "                upper = np.array(upper, dtype='uint8')\n",
        "                #이미지에 HSV 경계의 마스크 설정\n",
        "                mask = cv2.inRange(hsv, lower, upper)\n",
        "                #HSV 경계의 마스크 기준으로 이미지 표현\n",
        "                output = cv2.bitwise_and(frame, hsv, mask=mask)\n",
        "                number_of_total = cv2.countNonZero(mask)\n",
        "\n",
        "                cv2.imshow(\"original\", frame)\n",
        "                cv2.imshow(\"Fire\", output)\n",
        "\n",
        "                if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "                    break\n",
        "    vidCap.release()\n",
        "    cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYG8ejYmA1G4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}